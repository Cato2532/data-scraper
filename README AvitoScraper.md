# AvitoScraper

Скрипт для парсинга объявлений с Avito.  
Позволяет собирать данные о товарах: **название**, **цена**, **дополнительная информация**.  
Результаты выгружаются в CSV для дальнейшего анализа.

---

## Как работает
* Использует `requests` для загрузки HTML-страниц и `BeautifulSoup` для разбора.
* Сохраняет три поля для каждого объявления:
  - `name`  — заголовок объявления
  - `price` — цена (как текст, без нормализации)
  - `info`  — описание или характеристики
* Поддерживает защиту от дублей: одинаковые объявления не повторяются в итоговой таблице.

---

## Важное замечание
Avito **регулярно меняет классы в HTML-разметке**.  
В коде это выглядит как:
```python
soup.find_all("div", class_="iva-item-body-oMJBI")
snippet.find("div", class_="iva-item-title-KE8A9")
snippet.find("div", class_="price-priceContent-I4I3p")
snippet.find("div", class_="iva-item-bottomBlock-VewGa")
```
---

## Что делать, если парсер перестал находить данные?
1. Открой нужную страницу **Avito** в браузере.  
2. Наведи **правой кнопкой мыши** → выбери «Просмотреть код» (или *Inspect*).  
3. Найди HTML-блок с **названием**, **ценой** или **описанием**.  
4. Скопируй актуальное значение `class` и замени его в коде парсера.  

<img width="1433" height="651" alt="image" src="https://github.com/user-attachments/assets/09d22961-a989-41ea-84d1-d9def03aaea6" />

---

## Примечание об ограничениях и авторских правах

Этот скрипт **не нарушает авторские права Avito**, так как:

* Парсер принимает на вход только **одну конкретную страницу URL**, а не обходит сайт целиком.  
* Код предназначен исключительно для **учебных и исследовательских целей** — показать пример работы с HTML и `BeautifulSoup`.  
* Нет обхода защиты (CAPTCHA, авторизация, API Avito). Скрипт работает только с **открытыми публичными страницами**.  
* Для больших объёмов данных требуется вручную прописывать новые URL и запускать парсер снова.  
* Добавлена защита от дублей и остановка при повторяющихся данных, что ограничивает нагрузку на сайт.  

⚠️ Если нужен полноценный сбор больших массивов данных, используйте официальные API и соблюдайте правила Avito.
